{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d91fc730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RandomForestRegressor\n",
      ">mse=11132.567, est=-3448.867, cfg={'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      ">mse=1561.467, est=-4705.215, cfg={'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 50}\n",
      ">mse=613.307, est=-4698.607, cfg={'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 150}\n",
      ">mse=23165.546, est=-2060.178, cfg={'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 150}\n",
      ">mse=308.830, est=-4956.732, cfg={'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}\n",
      ">mse=730.909, est=-4775.501, cfg={'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 150}\n",
      ">mse=1001.482, est=-4756.966, cfg={'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 150}\n",
      ">mse=1378.946, est=-4701.893, cfg={'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}\n",
      ">mse=1869.385, est=-4642.382, cfg={'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}\n",
      ">mse=2835.415, est=-4680.132, cfg={'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 150}\n",
      "RandomForestRegressor Mean MSE: 4459.785 (std: 6925.044)\n",
      "Evaluating GradientBoostingRegressor\n",
      ">mse=10948.847, est=-3214.717, cfg={'learning_rate': 0.1, 'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50}\n",
      ">mse=1140.258, est=-4497.952, cfg={'learning_rate': 0.01, 'max_depth': 3, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 50}\n",
      ">mse=295.953, est=-4586.071, cfg={'learning_rate': 0.01, 'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50}\n",
      ">mse=23375.754, est=-1953.888, cfg={'learning_rate': 0.01, 'max_depth': 3, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 50}\n",
      ">mse=219.316, est=-4525.905, cfg={'learning_rate': 0.01, 'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50}\n",
      ">mse=435.967, est=-4580.249, cfg={'learning_rate': 0.01, 'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50}\n",
      ">mse=771.923, est=-4563.903, cfg={'learning_rate': 0.01, 'max_depth': 3, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 50}\n",
      ">mse=4740.999, est=-4372.137, cfg={'learning_rate': 0.2, 'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50}\n",
      ">mse=1608.378, est=-4372.013, cfg={'learning_rate': 0.01, 'max_depth': 3, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 50}\n",
      ">mse=2167.143, est=-4421.577, cfg={'learning_rate': 0.01, 'max_depth': 3, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "GradientBoostingRegressor Mean MSE: 4570.454 (std: 6995.677)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('forestfires.csv')\n",
    "\n",
    "# Preprocess data\n",
    "data['month'] = LabelEncoder().fit_transform(data['month'])\n",
    "data['day'] = LabelEncoder().fit_transform(data['day'])\n",
    "X = data.drop(['area'], axis=1).values\n",
    "y = data['area'].values\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Configure the outer cross-validation procedure\n",
    "cv_outer = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "# Define models and hyperparameters\n",
    "models_params = {\n",
    "    'RandomForestRegressor': {\n",
    "        'model': RandomForestRegressor(random_state=1),\n",
    "        'params': {\n",
    "            'n_estimators': [50, 100, 150],\n",
    "            'max_depth': [10, 20, 30],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4]\n",
    "        }\n",
    "    },\n",
    "    'GradientBoostingRegressor': {\n",
    "        'model': GradientBoostingRegressor(random_state=1),\n",
    "        'params': {\n",
    "            'n_estimators': [50, 100, 150],\n",
    "            'learning_rate': [0.01, 0.1, 0.2],\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'min_samples_split': [2, 5],\n",
    "            'min_samples_leaf': [1, 3]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Outer loop\n",
    "for name, mp in models_params.items():\n",
    "    outer_mse = []\n",
    "    print(f\"Evaluating {name}\")\n",
    "    for train_ix, test_ix in cv_outer.split(X_scaled):\n",
    "        # Split data\n",
    "        X_train, X_test = X_scaled[train_ix, :], X_scaled[test_ix, :]\n",
    "        y_train, y_test = y[train_ix], y[test_ix]\n",
    "\n",
    "        # Configure the inner cross-validation procedure\n",
    "        cv_inner = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "\n",
    "        # Define search\n",
    "        search = GridSearchCV(mp['model'], mp['params'], scoring='neg_mean_squared_error', cv=cv_inner, refit=True)\n",
    "\n",
    "        # Execute search\n",
    "        result = search.fit(X_train, y_train)\n",
    "\n",
    "        # Get the best performing model fit on the whole training set\n",
    "        best_model = result.best_estimator_\n",
    "\n",
    "        # Evaluate model on the hold out dataset\n",
    "        yhat = best_model.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, yhat)\n",
    "\n",
    "        # Store the result\n",
    "        outer_mse.append(mse)\n",
    "\n",
    "        # Report progress\n",
    "        print(f'>mse={mse:.3f}, est={result.best_score_:.3f}, cfg={result.best_params_}')\n",
    "\n",
    "    # Summarize the estimated performance of the model\n",
    "    print(f\"{name} Mean MSE: {np.mean(outer_mse):.3f} (std: {np.std(outer_mse):.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05446b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
